<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.--><!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit --><!DOCTYPE html>
<html><head><!--Google Tag Manager--><script class="gtm">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-W59SWTR');</script><!--End Google Tag Manager-->
</head>
<body><!--Google Tag Manager (noscript)--><noscript class="gtm"><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-W59SWTR" style="display:none;visibility:hidden" width="0"></iframe></noscript><!--End Google Tag Manager (noscript)-->

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header class="default" id="experiment-header">
  
    <div class="logo" id="experiment-header-logo">
      <!-- Enclose the logo image of your lab or write it in 
      text
      <img src="../images/logo.jpg" />
	-->
    </div>

    <div class="heading" id="experiment-header-heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.html">Speech Signal Processing Virtual Lab</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->

  </header>


  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
    
      <header class="heading" id="experiment-article-heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
        Expt-8: Linear Prediction Analysis of Speech
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav class="default" id="experiment-article-navigation">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div class="icon" id="experiment-article-section-1-icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg"/>
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div class="heading" id="experiment-article-section-1-heading">
            Objective
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
          <div class="content" id="experiment-article-section-1-content">	
            <p>
	      <!-- PUT CONTENT HERE -->

	      </p><ul>
	      <li><p> To study the characteristics of speech using linear prediction (LP) analysis.</p></li>
	      <li><p> To observe the LP spectrum and LP residual for voiced and unvoiced segments. </p></li>
	      <li><p> To study the effect of order of LP analysis (normalized error), autocorrelation of signal and LP residual for voiced and unvoiced segments. </p></li>
	      <li><p> To study the glottal pulse characteristics.</p></li>
<!--	      The primary objective of this experiment is the study
	      of the characteristics of speech using linear prediction
	      analysis. This includes observing the LP spectrum and LP
		residual for voiced and unvoiced segments and 
	 	studying the effect of order of LP analysis (normalized error),
		autocorrelation of signal and LP residual for voiced and unvoiced
		segments, and study of glottal pulse shapes. -->
		</ul> 
        </div>


      </section>

      <!-- Second section of the article-->
      <section id="experiment-article-section-2">
        
        <div class="icon" id="experiment-article-section-2-icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/theory.jpg"/>
	</div>
	<div class="heading" id="experiment-article-section-2-heading">
          Tutorial
        </div>

        <div class="content" id="experiment-article-section-2-content">
	    <!-- PUT CONTENT HERE -->
<p>
</p><h3>Source-system modeling of speech signals using LP analysis</h3>
<p></p>
<p>
The vocal tract system can be modeled as a time-varying all-pole filter using segmental analysis.
The segmental analysis corresponds to the processing of speech as short (10-30 ms) overlapped (5-15 ms) windows.
The vocal tract system is assumed to be stationary within the window and is modeled as an all-pole filter of order \( p \) using linear prediction (LP) analysis.
The LP analysis works on the principle that a sample value in a correlated, stationary sequence can be predicted as a linear weighted sum of the past few (\( p \)) samples.
If \( s(n) \) denotes a sequence of speech samples, then the predicted value at the time instant \( n \) is given by
$$ \hat{s}(n) = \sum_{k=1}^{p}{a_k~s(n-k)} \qquad (1) $$
where \( \{a_k\},~k=1,2,...,p \) is the set of linear predictor coefficients (LPC) and \(p\) is the order of the LP filter. 
The error at time \(n\) and the sum of squared errors \( E \) are given by
$$ r(n)~=~s(n)~-~\hat{s}(n) \qquad(2)$$
$$ E=~\sum_{n}{r^2(n)} \qquad(3) $$
The cost function \( E \) is minimized with respect to \( \{a_i\},~i=1,2,...,p \) over the interval \( {-\infty}~{\leq}~n~{\leq}~{\infty} \) (autocorrelation formulation) as,
$$ {\partial{E}}/{\partial{a_i}}~=~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~{\leq}~i~{\leq}~p \qquad(4)$$
This minimization leads to a set of normal equations,
$$ \sum_{k=1}^{p}{a_k~R(i-k)} = -R(i)~~~~~~~~~~~~~~1~{\leq}~i~{\leq}~p \qquad(5)$$
where 
$$ R(i) = \sum_{n=-\infty}^{\infty}s(n)~s(n+i)~~~~~~~~~~-{\infty}~{\leq}~i~{\leq}~{\infty} \qquad(6) $$
is the autocorrelation sequence. The solution of these normal equations gives the values of the predictor coefficients \( \{a_k\},~k=1,2,...,p \).
The error signal \( r(n) \) obtained by inverse filtering the speech signal
is referred to as the LP <i>residual</i>.
The smooth variations (highly correlated) in the speech signal are captured by the LPCs and are attributed to the vocal tract characteristics.
The complex poles of the LP filter occur as conjugate pairs, and each pair represents a resonator cavity, with a maximum response at a frequency (called as <i>resonant frequency</i>) where the poles are located on the z-plane.
The vocal tract can be considered as a cascade of resonator cavities with different shapes and sizes.
The resonant frequencies of these cavities are referred to as <i>formants</i>.
The LP residual signal has large error values at regular intervals and can be attributed to the periodic impulses of excitation.
Hence the LP residual is a good approximation to the excitation source signal and can be used further to extract the excitation source characteristics.
A segment of voiced speech (windowed), frequency response of the inverse filter and the corresponding LP residual are shown in Figure 1.
</p>

<p>
<img src="media/lpinvfilter.png"/><br/>
<b>Figure 1:</b> <i>Inverse filtering the speech signal for estimating the excitation source (LP residual) signal.</i> <br/>
</p>

<h2>Short time spectrum, LP spectrum and Inverse spectrum</h2>
<p>
The short-time spectrum consists of range of frequencies (magnitude and
phase components) that are present in a small segment (10-30 ms) of a
signal. 
An inverse spectrum \(A(j\omega)\) is an all-zero model derived from \(A(z)\). 
The LP spectrum is an all-pole model given by \(\frac{1}{A(j\omega)}\).
The LP spectrum can approximate the envelope of the short-time spectrum depending on the choice of LP order.
The gross envelope is captured at low LP orders such as 1 or 3.
The short-time spectral envelope is finely matched as the LP order increases.
One of the main issues in LP analysis is the choice of appropriate LP order.
Figures 2 and 3 show the short-time spectrum, LP spectrum and the inverse LP spectrum for a segment of voiced (/a/) and unvoiced speech (/s/) respectively.
</p>
<br/>
<p>
<img alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/fig2.eps}}" src="media/img3.png" style="border: 0px solid ; width: 680px; height: 454px;"/><br/>
<strong>Figure 2:</strong> <i class="sans">(a)
Segment of voiced speech /a/ and its (b) short
time spectrum, (c) LP spectrum and (d) inverse spectrum (LP order: 10).<br/>
</i><br/>
<br/>
</p>

<p>
<img alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/fig3.eps}}" src="media/img5.png" style="border: 0px solid ; width: 680px; height: 454px;"/>
<br/>
<a name="fig:unvoiced-spec"></a><a name="187"></a>
<strong>Figure 3:</strong>
<i class="sans">(a) Segment of unvoiced speech /s/ and its (b) short
time spectrum, (c) LP spectrum and (d) inverse spectrum (LP order: 10).<br/>
</i>
</p>

<h2>LP residual for voiced and unvoiced segments </h2>

<p>LP residual signal is obtained by passing the speech signal
through inverse filter designed with LP coefficients (LPCs). The block
diagram of the inverse filter is shown in Figure 4.<br/>
</p>
<p>
<img alt="\resizebox*{12cm}{3cm}{\includegraphics{figures/inversefilter.eps}}" src="media/img6.png" style="border: 0px solid ; width: 543px; height: 135px;"/><br/>
<strong>Figure 4:</strong> <i class="sans">Inverse filter to obtain LP
residual signal from speech signal.</i>
</p>

<p>
Voiced and unvoiced speech segments and their LP residual signals
are shown in Figure 5.
</p>
<p>
<img alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure8.eps}}" src="media/img7.png" style="border: 0px solid ; width: 680px; height: 454px;"/><br/>
<a name="fig:residuals"></a><a name="191"></a><strong>Figure 5:</strong>
<i class="sans">(a) Segment of voiced speech /a/ and its (b) LP
residual signal, (c) segment of unvoiced speech /s/ and its (d) LP
residual signal (LP order: 10).</i><br/>
</p>
<br/>
<br/>

<h2>Autocorrelation function for voiced/unvoiced speech segments and their LP residuals
</h2>
<br/>
<ul>
<li>Autocorrelation function of the signal \(x[n]\) is computed as <br/>
$$
R[\tau]=\sum\limits_{n=-\infty}^{+\infty}x[n]x[n+\tau] \qquad(7)
$$
</li>
<li>The autocorrelation function for the voiced speech segment and
its LP residual signal is shown in FigureÃ‚Â 6.</li>
<br/>
<img alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure6.eps}}" src="media/img9.png" style="border: 0px solid ; width: 680px; height: 454px;"/><br/>
<strong>Figure 6: </strong><i class="sans">(a) Segment of voiced speech /a/ and
its (b)
autocorrelation function, (c) LP residual for the voiced speech segment
and its (d) autocorrelation function (LP order: 10).</i><br/>
<br/>
<li>The autocorrelation function for the unvoiced speech segment and
its LP residual signal is shown in Figure 7.<br/>
<img alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure7.eps}}" src="media/img10.png" style="border: 0px solid ; width: 680px; height: 454px;"/><br/>
 </li>
<br/>
<strong>Figure 7: </strong><i class="sans">(a) Segment of unvoiced
speech /s/ and its (b)
autocorrelation function, (c) LP residual for the unvoiced speech
segment and its (d) autocorrelation function (LP order: 10).<br/>
<br/>
<br/>
</i>
</ul>

<h2>Glottal pulse shape in voiced portion of a speech signal
</h2>
<ul>
<li>By integrating the LP residual we can obtain the glottal pulse
shape, it is also known as glottal volume velocity. </li>
<li>A segment of voiced speech its LP residual and glottal pulse
(glottal volume velocity) waveforms are shown in FigureÃ‚Â 8. </li>
<img alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure5.eps}}" src="media/img11.png" style="border: 0px solid ; width: 670px; height: 457px;"/><br/>
<strong>Figure 8: </strong> <i class="sans">(a) Segment of voiced
speech /a/, its (b) LP residual and (c) glottal pulse waveform (LP order: 10).</i>
</ul>
<ul>
<br/>
<br/>
<br/>
</ul>
<h2>LP spectrum for different LP
orders
</h2>
<ul>
<li>Compute LPCs for different LP orders (14, 10, 6, 3 and 1), and
compute LP spectrum for each set of LPCs. </li>
<li>A segment of voiced speech and its LP spectrum for different LP
orders (14, 10, 6, 3 and 1) are shown in FigureÃ‚Â 9. </li>
<img alt="\resizebox*{15cm}{20cm}{\includegraphics{figures/fig4.eps}}" src="media/img14.png" style="border: 0px solid ; width: 681px; height: 907px;"/><br/>
<strong>Figure 9:</strong> <i class="sans">(a) Segment of voiced
speech /a/, its LP spectrum for the LP order (b) 14, (c) 10, (d) 6, (e)
3 and (f) 1 </i> 
</ul>
<ul>
<br/>
<h2>Normalized error for different LP orders for voiced/unvoiced speech
segments
</h2>
<ul>
<li>Normalized error is obtained by normalizing the LP residual
energy with respect to speech signal energy. 
$$\eta = \frac{E_r}{E_s},  \qquad(8) $$
where \(E_r=\sum_{n=0}^{N-1}e^2[n]\) and \(E_s=\sum_{n=0}^{N-1}s^2[n]\) denote the residual and signal energies, respectively.
</li>
<li>Normalized error plots for voiced and unvoiced segments of speech for
different LP orders are shown in Figure 10</li>
</ul>
<img &gt;="" alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure4.eps}}" src="media/img19.png" style="border: 0px solid ; width: 681px; height: 454px;"/><br/>
<strong>Figure 10:</strong> <i class="sans">Normalized error for
voiced and unvoiced speech segments for different LP orders. </i>
<br/>
<br/>
</ul>

        </div>				
				
       
      </section>


      <section id="experiment-article-section-3">
        
        <div class="icon" id="experiment-article-section-3-icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/procedure.jpg"/>
	</div>
      <!-- The heading for the section can be enclosed in a 
        div tag. -->
        <div class="heading" id="experiment-article-section-3-heading">
          Procedure
        </div>

        <!-- Write the section content inside a paragraph 
        element, we can also include images with <img> tag -->
        <div class="content" id="experiment-article-section-3-content">

	    <!-- PUT CONTENT HERE -->
	    <ul>
<li><p>Select one of the provided speech utterances and click on the load button.</p></li>
<li><p>Select a short segment (20-50 ms) of voiced speech (say a vowel), using 'Zoom to selection' button, and compute the short-time and LP spectrum by clicking on the spectrum button.</p></li>
<li><p>The windowed signal, the log spectrum and the LP log spectrum are displayed.</p></li>
<li><p>Increase the LP order from the default value 1, to values provided in the drop down box. Click on the spectrum button to recompute the spectra.</p></li>
<li><p>Observe that the LP log spectrum approximates the short-time spectral envelope (i.e., the formants) better with increases LP order. </p></li>
<li><p>As the LP order is increased to a very large value, say 40, the LP spectrum tries to approximate the short-time spectral envelope more closely thereby approximating peaks due to pitch harmonics.</p> </li>
<li><p>Study the effect of preemphasis flag on the LP spectrum.</p></li>
<li><p>Compute the LP residual signal for different LP orders by clicking on the residual button.</p></li>
<li><p>The correlations in the input segment of speech can be seen to be gradually removed in the LP residual signal as the LP order is increased.</p></li>
<li><p>The LP residual signal for an LP order of 10 or above removes most of the correlations in the input signal, and the resulting signal looks like a train of impulses.</p></li>
<li><p>Repeat the experiment by selecting an unvoiced segment of speech, say a fricative /s/.</p></li>
<li><p>Write a brief note on the observations. </p></li>
	    </ul>

        </div>
        

      </section>


      <section id="experiment-article-section-4">

        <div class="icon" id="experiment-article-section-4-icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/simulation.jpg"/>
	</div>

        <div class="heading" id="experiment-article-section-4-heading">
          Experiment
        </div>

        <div class="content" id="experiment-article-section-4-content">
<p>
	    <!-- PUT CONTENT HERE -->
</p><p>
<em>Note: Speech segments are sampled at 8KHz (\(F_s = 8000 Hz\)).</em> </p>
<applet archive="media/lpSpectrumAnalysisS.jar" code="audioTransport/SVLAudioTool.class" height="700" title="Java" width="950">
               <param name="foo" value="bar"></param>
        Please install the latest version of the Java plugin for your browser. <br/>
        </applet>
<p></p>
</div>

      </section>

      <section id="experiment-article-section-5">
   
        <div class="icon" id="experiment-article-section-5-icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/manual.jpg"/>
	</div>

        <div class="heading" id="experiment-article-section-5-heading">
          Observations
        </div>

        <div class="content" id="experiment-article-section-5-content">
	    <!-- PUT CONTENT HERE -->
<ul>
<li><p>Short time spectrum gives both source and system information. The
envelope of the spectrum gives system information (i.e., resonances in
terms of formant frequencies) and spectral ripples (fine variations)
give source information (i.e., pitch harmonics). It is a real and even
function of Ãƒï¿½Ã¢â‚¬Â°.</p> </li>
<li><p>The linear prediction (LP) analysis models the vocal tract
system. LP spectrum is observed to be an envelope of short time spectrum
(smoothed version of short time spectrum) and the peaks in LP spectrum
indicate the formant frequencies (resonances) of the vocal tract
system. With observation it is evident that the LP spectrum is derived
from an all-pole filter.</p> </li>
<li><p>The inverse spectrum is observed to be reciprocal of the LP
spectrum. Therefore, we can observe the valleys corresponding to the peaks
in LP spectrum. It is represented by an all-zero filter.</p></li>
<li><p>For voiced speech segment its LP residual is observed to be
periodic. In LP residual signal, peak amplitudes refers to closure of
vocal folds (glottal closure), where the prediction is poor therefore
its results as maximum error. </p><br/>
</li>
<li><p>The periodicity in LP residual also indicate the pitch
information.</p></li>
<li><p>LP residual is a result of passing the speech signal through
inverse filter (i.e., removing the vocal tract information). This is
also considered to be the excitation signal (source information).</p></li>
<li><p>LP residual for unvoiced speech segment looks like random noise.
This is because the unvoiced speech signal has no periodicity and looks like random
noise (no relations among the samples). </p></li>
<li><p>The basic property of the autocorrelation function (even
symmetry) is evident in all (voiced/unvoiced speech and LP residual
signals) the plots. </p><br/>
</li>
<li><p>The samples in a voiced speech segment are highly correlated,
therefore we will observe the peaks other than center are also
prominent. As voiced speech is periodic, it is inherited in its
autocorrelation function also.</p> <br/>
</li>
<li><p>In LP residual, the correlation among the samples is less,
therefore its autocorrelation function contains the peaks at pitch
rate. Hence autocorrelation function of a LP residual is useful for
pitch computation. </p><br/>
</li>
<li><p>The autocorrelation function of an unvoiced speech segment shows
a major peak at the center and other peaks are not significant, since
unvoiced speech signal appears like random signal.</p></li>
<li><p>The autocorrelation function for the LP residual of an unvoiced
speech segment shows a dominant peak at the center and no other peaks
in rest of the portion. This is because, unvoiced speech itself looks
like random (no correlation among the samples) and its residual
reflects still random.</p><br/>
</li>
<li><p>Glottal pulse shape shows the change in volume of air. It is also
referred to as glottal volume velocity. </p><br/>
</li>
<li><p>From the glottal pulse waveform, it is observed that volume of
air and its pressure will be maximum at the instant of closure.
Following this is the opening of the vocal folds, as a result of which
the air pressure decreases.</p></li>
<li><p>LP order determines to some extent the accuracy with which speech
production mechanism is modeled. </p><br/>
</li>
<li><p>LP analysis uses an all-pole model to characterize the vocal tract system
by capturing the resonances with spectrum and source information with LP
residual (inverse filter i.e., all-zero filter).</p> <br/>
</li>
<li><p>LP order determines the number of resonances that can be captured
by
the model. The maximum number of resonances captured by the model with
LP order <span class="MATH">P</span> is P/2.</p> <br/>
</li>
<li><p>The length of the vocal tract from glottis to lips is
approximately 17
cm. This can generate four to five prominent resonances in 0-4 KHz
range. These resonances can be captured with the LP model of order 10.
We also should take care of radiation and windowing effects. Therefore
with LP order 10-14 we can model the system by capturing required
resonances.Ã‚Â </p> </li>
<li><p>System with LP order more than 14 will introduce the spurious
resonances, which leads improper representation of the vocal tract
system.</p></li>
<!--
<li>Normalized error for voiced speech signal reduces as the LP order
is varied from 0 to 15, since the vocal tract system (speech production
mechanism) is modeled more accurately as LP order varying from 0 to
15.&nbsp;</li>
<ul>
<li>P=0, no approximation, therefore maximum error&nbsp;</li>
<li>P=1, only one coefficient used for prediction, therefore error
is slightly less compared to that of P=0&nbsp;</li>
<li>P=10, model correctly approximates the resonances of the vocal
tract system, which leads to minimum error&nbsp;</li>
<li>P ÃƒÂ¢Ã¢â‚¬Â°Ã‚Â¥ 10
also results the correct modeling of the vocal tract system, which
leads to similar error as that of model with P=10&nbsp;</li>
<li>For unvoiced speech signal, as the signal and residual energies
remains reasonable same, change in error as function of LP order is
relatively insensitive. Unvoiced speech signal itself appears like
random noise, therefore the prediction will remains poor even though if
we increase the LP order. Therefore both unvoiced speech signal and its
LP residual appears like noise, hence the normalized error for unvoiced
speech signal won't depend on the LP order.</li>
-->
</ul>

          </div>

        </section>

        <section id="experiment-article-section-6">
      
          <div class="icon" id="experiment-article-section-6-icon">
	    <img src="../images/quizzes.jpg"/>
	  </div>

          <div class="heading" id="experiment-article-section-6-heading">
            Assessment 
          </div>

          <div class="content" id="experiment-article-section-6-content">
<ol>
           		<li> What is the minimum number of speech samples required to compute the LP coefficients of order p?
			</li><li> Explain the differences between autocorrelation and autcovariance formulations of LP analysis? Which is better and why?</li>
			<li> Suggest an algorithm for voiced/non-voiced region separation using:
			<ol>
				<li> LP residual energy</li>
				<li> Periodicity information in the LP residual</li>
			</ol>
			</li><li> Write an Octave/Scilab program that implements the above algorithms of 3 (1) and 3 (2)</li>
			</ol>
         </div>

        </section>

        
			


 


		
        <section id="experiment-article-section-9">
   
          <div class="icon" id="experiment-article-section-9-icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/readings.jpg"/>
	  </div>

          <div class="heading" id="experiment-article-section-9-heading">
            References
          </div>

          <div class="content" id="experiment-article-section-9-content">
<ul>
			<li><p> <i>Digital Processing of Speech Signals</i>, L.R. Rabiner and L.R. Schafer, Chapter 8</p></li>
			<li><p> <i>Discrete-Time Speech Signal Processing</i>, Thomas F. Quatieri , Chapter 5</p></li>
</ul>     
     
          </div>

        </section>

      </div>


    <!-- An article can have a sidebar that contain related 
    links and additional material (however it is kept optional 
    at this moment) -->
    <aside class="default" id="lab-article-sidebar">
      <!-- put the content that you want to appear in the 
      sidebar -->	
    </aside>


    <!-- Article footer can display related content and 
    additional links -->						
    <footer class="default" id="lab-article-footer">
      <!-- Put the content that you want to appear here -->
    </footer>

  </article>


  <!-- Links to other labs, about us page can be kept the lab 
  footer-->
  <footer class="default" id="lab-footer">
    <!-- Put the content here-->
  </footer>



<footer class="heading" id="lab-header">
    <!-- Put the content here-->
    <div class="heading" id="lab-header-heading">
    <!-- Write the name of your lab and link it to the home page
    of your lab. -->
        <center>
        <table><tbody><tr>
                <td><a href="http://speech.iiit.ac.in/" target="_blank"><font size="-3">Developed at the Speech and Vision Lab, IIIT Hyderabad</font></a></td>
        </tr></tbody></table>
        </center>
    </div>


  </footer>


</div>		
<script src="../js/MathJax/MathJax.js?config=default" type="text/javascript"></script>



</body></html>